{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enD6N3SDqJ0M"
   },
   "source": [
    "<div id=\"container\" style=\"position:relative;\">\n",
    "<div style=\"float:left\"><h1>  Statistics </h1></div>\n",
    "<div style=\"position:relative; float:right\"><img style=\"height:65px\" src =\"https://drive.google.com/uc?export=view&id=1EnB0x-fdqMp6I5iMoEBBEuxB_s7AmE2k\" />\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUXSs93HqJ0O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSuww-W6qJ0R"
   },
   "source": [
    "In this lesson, we're going to review some basic statistics information, then learn more advanced techniques and terms.\n",
    "\n",
    "\n",
    "## Statistics\n",
    "\n",
    "### Single Variable Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Moavcf4YqJ0S"
   },
   "source": [
    "**Central Tendency**\n",
    "\n",
    "*  **Mean**:  this is the term for what we generally call an \"average\".  We add all of the numbers in our data set, and then divide by the size of the set.  Symbolically, if $A = \\{a_1,a_2,\\ldots,a_n\\}$ is our data set, then the arithmetic mean (denoted $\\bar{A}$) is computed as: \n",
    "$$ \\begin{align}\n",
    "\\bar{A} &=  \\frac{1}{n}(a_1+a_2+\\ldots+a_n) \\\\\n",
    "&= \\frac{1}{n}\\sum_{i=1}^na_i\n",
    "\\end{align}$$\n",
    "* **Median**: for a given data set (of numbers), the median is the number that separates the top half of the data from the bottom half.  If the size of the data set is even (so there is no single data point in the middle), the median is given by the mean of the two middle values, after arranging the data into ascending order.\n",
    "* **Mode**: the mode is the value that occurs most frequently in a data set.\n",
    "\n",
    "**Dispersion**\n",
    "\n",
    "* **Variance**: The _variance_ of a dataset is the average of the squared differences between each data point and the mean.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(X) &= \\frac{1}{n}\\left((x_1-\\bar{X})^2+(x_2-\\bar{X})^2+\\ldots+(x_n-\\bar{X})^2\\right) \\\\\n",
    "&= \\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{X})^2\n",
    "\\end{align}$$  \n",
    "\n",
    "\n",
    "\n",
    "* **Standard Deviation**: the standard deviation is the square root of the variance.  One useful property of the standard deviation is that it is in the same units as the original data set (unlike the variance).  A low standard deviation implies the data is clustered near the mean, whereas a high standard deviation implies the data has a tendency to be further from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3I2FrBLAqJ0T"
   },
   "source": [
    "We can use in-built NumPy functions to calculate statistics of series objects that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "267EFqPhqJ0T",
    "outputId": "62064b7e-4f2f-424f-ab95-d0b96b5cb52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "3.0\n",
      "1.5811388300841898\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "print(s.mean())\n",
    "print(s.median())\n",
    "print(s.std())\n",
    "print(s.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrfZkPPrqJ0Z"
   },
   "source": [
    "Let's practice using the Anscombe's quartet dataset. This dataset can be found in Synapse under today's lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AItN9xzPqJ0Z"
   },
   "outputs": [],
   "source": [
    "anscombe = pd.read_csv('data/anscombe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kO1rluKtqJ0b",
    "outputId": "af9a6bff-d9aa-4438-b990-2e648861cdc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8.04</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>6.95</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>7.58</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8.81</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>8.33</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>9.96</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7.24</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4.26</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>10.84</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>4.82</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>5.68</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>9.14</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>8.14</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>8.74</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>8.77</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>9.26</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>8.10</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>6.13</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>3.10</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12</td>\n",
       "      <td>9.13</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>7.26</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>4.74</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>7.46</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>6.77</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>12.74</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>7.11</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11</td>\n",
       "      <td>7.81</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>8.84</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>6.08</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>5.39</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12</td>\n",
       "      <td>8.15</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>6.42</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>5.73</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>6.58</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8</td>\n",
       "      <td>5.76</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>7.71</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8</td>\n",
       "      <td>8.84</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8</td>\n",
       "      <td>8.47</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>7.04</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>5.25</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>19</td>\n",
       "      <td>12.50</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>5.56</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8</td>\n",
       "      <td>7.91</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>6.89</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X      Y Dataset\n",
       "0   10   8.04       I\n",
       "1    8   6.95       I\n",
       "2   13   7.58       I\n",
       "3    9   8.81       I\n",
       "4   11   8.33       I\n",
       "5   14   9.96       I\n",
       "6    6   7.24       I\n",
       "7    4   4.26       I\n",
       "8   12  10.84       I\n",
       "9    7   4.82       I\n",
       "10   5   5.68       I\n",
       "11  10   9.14      II\n",
       "12   8   8.14      II\n",
       "13  13   8.74      II\n",
       "14   9   8.77      II\n",
       "15  11   9.26      II\n",
       "16  14   8.10      II\n",
       "17   6   6.13      II\n",
       "18   4   3.10      II\n",
       "19  12   9.13      II\n",
       "20   7   7.26      II\n",
       "21   5   4.74      II\n",
       "22  10   7.46     III\n",
       "23   8   6.77     III\n",
       "24  13  12.74     III\n",
       "25   9   7.11     III\n",
       "26  11   7.81     III\n",
       "27  14   8.84     III\n",
       "28   6   6.08     III\n",
       "29   4   5.39     III\n",
       "30  12   8.15     III\n",
       "31   7   6.42     III\n",
       "32   5   5.73     III\n",
       "33   8   6.58      IV\n",
       "34   8   5.76      IV\n",
       "35   8   7.71      IV\n",
       "36   8   8.84      IV\n",
       "37   8   8.47      IV\n",
       "38   8   7.04      IV\n",
       "39   8   5.25      IV\n",
       "40  19  12.50      IV\n",
       "41   8   5.56      IV\n",
       "42   8   7.91      IV\n",
       "43   8   6.89      IV"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anscombe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "01gO55GOqJ0e"
   },
   "source": [
    "Recall that Anscombe's quartet is four datasets with very similar descriptive statistics. We'll plot the four below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "899W0FwLqJ0f",
    "outputId": "4b8aca93-eaf2-4c59-d6b7-022d87c40684"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1132e2278>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anscombe[anscombe['Dataset'] == \"I\"].plot.scatter(x='X', y='Y')\n",
    "anscombe[anscombe['Dataset'] == \"II\"].plot.scatter(x='X', y='Y')\n",
    "anscombe[anscombe['Dataset'] == \"III\"].plot.scatter(x='X', y='Y')\n",
    "anscombe[anscombe['Dataset'] == \"IV\"].plot.scatter(x='X', y='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHqHn6TdqJ0i"
   },
   "source": [
    "Verify which descriptive statistics are equal across each of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYUC7lTsqJ0j",
    "outputId": "59c8dd7d-c5ad-4f66-b516-2e73473a82e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">X</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.500909</td>\n",
       "      <td>7.58</td>\n",
       "      <td>2.031568</td>\n",
       "      <td>4.127269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>II</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.500909</td>\n",
       "      <td>8.14</td>\n",
       "      <td>2.031657</td>\n",
       "      <td>4.127629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>III</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.11</td>\n",
       "      <td>2.030424</td>\n",
       "      <td>4.122620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.500909</td>\n",
       "      <td>7.04</td>\n",
       "      <td>2.030579</td>\n",
       "      <td>4.123249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X                                Y                           \n",
       "        mean median       std   var      mean median       std       var\n",
       "Dataset                                                                 \n",
       "I          9      9  3.316625  11.0  7.500909   7.58  2.031568  4.127269\n",
       "II         9      9  3.316625  11.0  7.500909   8.14  2.031657  4.127629\n",
       "III        9      9  3.316625  11.0  7.500000   7.11  2.030424  4.122620\n",
       "IV         9      8  3.316625  11.0  7.500909   7.04  2.030579  4.123249"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anscombe.groupby('Dataset').agg(['mean', 'median', 'std', 'var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MeziIe7qJ0n"
   },
   "source": [
    "### Covariance\n",
    "\n",
    "The descriptive statistics that we've studied so far give us ways to summarize aspects of a single column of data. _Covariance_ and _correlation_ are ways to summarize how two columns of data interact with each other. Given two equal-length lists of numbers $X=(x_1, x_2, ..., x_N)$ and $Y=(y_1, y_2, ..., y_N)$, the covariance of $X$ and $Y$ is given by the following formula.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Cov}(X,Y) &= \\frac{1}{N}\\left( (x_1 - \\bar{X})(y_1 - \\bar{Y}) + (x_2 - \\bar{X})(y_2 - \\bar{Y}) + ... + (x_N - \\bar{X})(y_N - \\bar{Y}) \\right) \\\\\n",
    "&= \\frac{1}{N}\\sum_{i=1}^N (x_i - \\bar{X})(y_i - \\bar{Y})\n",
    "\\end{align}$$\n",
    "\n",
    "*Questions to think about*\n",
    "- The covariance formula is an average. Each term in the covariance formula is a product $(x_k - \\bar{X})(y_k - \\bar{Y})$. How can that product be negative? How can it be positive? How can it be zero?\n",
    "- How can the whole average be positive, negative, or zero?\n",
    "\n",
    "Generally, when two columns have a high (positive) covariance, it means that they move together in some sense -- when one is large, the other is large, and vice versa.\n",
    "\n",
    "**Problem:** Using only the built-in functions `sum` and `len`, write a function `covariance(X,Y)` that takes two equal-length lists of numbers and outputs the covariance of the two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqP1Mj81qJ0o"
   },
   "outputs": [],
   "source": [
    "def covariance(x,y):\n",
    "    assert len(x) == len(y)  # This is a useful trick for on-the-fly bug swatting\n",
    "    \n",
    "    # write your function here\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOoGGrUiqJ0z"
   },
   "source": [
    "#### The Covariance Matrix\n",
    "The covariance is defined pairwise -- that is, there is only a covariance between _pairs_ of variables. To look at covariances within an entire dataset, we can use something called the _covariance matrix_. For a dataset with $n$ columns, the covariance matrix of that dataset is an $n\\times n$ matrix where the $ij$-th entry is the covariance of the $i$-th and $j$-th columns. Pandas gives you a covariance matrix of a dataframe using the `df.cov()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SK8nVzphqJ00",
    "outputId": "df72e5eb-e03d-4698-e204-6fdc0b648bba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>11.000</td>\n",
       "      <td>5.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>5.501</td>\n",
       "      <td>4.127269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X         Y\n",
       "X  11.000  5.501000\n",
       "Y   5.501  4.127269"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anscombe.loc[anscombe['Dataset'] == 'I', ['X', 'Y']].cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCuKh325qJ03"
   },
   "source": [
    "**Question:** What's along the diagonals?\n",
    "\n",
    "**Problem:** Check the covariance of X and Y for each dataset in Anscombe's quartet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9b0X9SXqJ03",
    "outputId": "006d8df6-9959-4fb6-fb68-cad7bb729533"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">I</th>\n",
       "      <th>X</th>\n",
       "      <td>11.000</td>\n",
       "      <td>5.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>5.501</td>\n",
       "      <td>4.127269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">II</th>\n",
       "      <th>X</th>\n",
       "      <td>11.000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>5.500</td>\n",
       "      <td>4.127629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">III</th>\n",
       "      <th>X</th>\n",
       "      <td>11.000</td>\n",
       "      <td>5.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>5.497</td>\n",
       "      <td>4.122620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">IV</th>\n",
       "      <th>X</th>\n",
       "      <td>11.000</td>\n",
       "      <td>5.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>5.499</td>\n",
       "      <td>4.123249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X         Y\n",
       "Dataset                    \n",
       "I       X  11.000  5.501000\n",
       "        Y   5.501  4.127269\n",
       "II      X  11.000  5.500000\n",
       "        Y   5.500  4.127629\n",
       "III     X  11.000  5.497000\n",
       "        Y   5.497  4.122620\n",
       "IV      X  11.000  5.499000\n",
       "        Y   5.499  4.123249"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one option\n",
    "anscombe.groupby(\"Dataset\").agg(\"cov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3Q8p0H1qJ07"
   },
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBvXcms6qJ08"
   },
   "source": [
    "When $X$ and $Y$ move together, then $\\text{Cov}(X,Y) \\gg 0$, and when they move in opposite directions, then $\\text{Cov}(X,Y) \\ll 0$. \n",
    "\n",
    "But there's still a problem: how big is big? Covariance is very sensitive to units. If $X$ is measured in inches, $Y$ is measured in feet, and $Z$ is just $X$ in feet, then we would have $\\text{Cov}(Z,Y) = 12\\text{Cov}(X,Y)$, even though $Z$ and $X$ are measuring the same thing. So there's no way to know in a vacuum when the covariance is large. One solution to this is to use a normalized version of the covariance. This is known as the Correlation, and it is computed as\n",
    "\n",
    "$\\text{Cor}(X,Y) = \\frac{\\text{Cov(X,Y)}}{\\text{SD}(X)\\text{SD}(Y)}$\n",
    "\n",
    "This number is called Pearson's correlation coefficient, and is sometimes denoted by the Greek letter $\\rho$, in which case we write the correlation between datasets $X$ and $Y$ as $\\rho_{XY}$.\n",
    "\n",
    "The number $\\rho_{XY}$ is always between 1 and -1. A correlation of 1 corresponds to a perfect linear relationship with a positive slope, and a correlation of -1 corresponds to a perfect linear relationship with a negative slope.\n",
    "\n",
    "\n",
    "We can define the _Correlation Matrix_ analogously to the covariance matrix. This is helpfully built for us in Pandas, and is useful to look at. Let's use it with the diamonds dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ux45rqgTqJ08",
    "outputId": "129f7e92-1c1e-47a6-a8ad-36839d4077d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>0.170527</td>\n",
       "      <td>0.923075</td>\n",
       "      <td>0.975987</td>\n",
       "      <td>0.889799</td>\n",
       "      <td>0.973268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <td>0.024126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.292511</td>\n",
       "      <td>-0.011173</td>\n",
       "      <td>-0.028646</td>\n",
       "      <td>-0.036580</td>\n",
       "      <td>0.092915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <td>0.170527</td>\n",
       "      <td>-0.292511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118126</td>\n",
       "      <td>0.183609</td>\n",
       "      <td>0.159047</td>\n",
       "      <td>0.142370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.923075</td>\n",
       "      <td>-0.011173</td>\n",
       "      <td>0.118126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0.809325</td>\n",
       "      <td>0.880184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.975987</td>\n",
       "      <td>-0.028646</td>\n",
       "      <td>0.183609</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909454</td>\n",
       "      <td>0.988819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.889799</td>\n",
       "      <td>-0.036580</td>\n",
       "      <td>0.159047</td>\n",
       "      <td>0.809325</td>\n",
       "      <td>0.909454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.973268</td>\n",
       "      <td>0.092915</td>\n",
       "      <td>0.142370</td>\n",
       "      <td>0.880184</td>\n",
       "      <td>0.988819</td>\n",
       "      <td>0.918352</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table     price         x         y         z\n",
       "carat  1.000000  0.024126  0.170527  0.923075  0.975987  0.889799  0.973268\n",
       "depth  0.024126  1.000000 -0.292511 -0.011173 -0.028646 -0.036580  0.092915\n",
       "table  0.170527 -0.292511  1.000000  0.118126  0.183609  0.159047  0.142370\n",
       "price  0.923075 -0.011173  0.118126  1.000000  0.886250  0.809325  0.880184\n",
       "x      0.975987 -0.028646  0.183609  0.886250  1.000000  0.909454  0.988819\n",
       "y      0.889799 -0.036580  0.159047  0.809325  0.909454  1.000000  0.918352\n",
       "z      0.973268  0.092915  0.142370  0.880184  0.988819  0.918352  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = pd.read_csv('data/diamonds.csv')\n",
    "diamonds.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zX-FhEsgqJ0_"
   },
   "source": [
    "That's a lot of numbers to look at. Seaborn has a useful way to visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2keVA82qJ0_",
    "outputId": "e7f666d3-54e4-4422-b9ab-5ee479e2b125"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a19ad0e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(diamonds.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7Qo2arTqJ1B"
   },
   "source": [
    "We notice that the diagonal entries are all 1, because each column is maximally correlated with itself.  The correlation between `A` and `B` is ~0.857, which is relatively close to 1.  This means the values in the columns tend to move together (i.e. there is a strong linear relationship between `A` and `B`).<br> \n",
    "\n",
    "**Exercise:** Let's load in the `timeseries_1.csv` price series, and compute the correlation between the different price columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vs5lNasQqJ1B"
   },
   "source": [
    "## Probability\n",
    "\n",
    "There are a number of different interpretations of what \"probability\" means.  The Bayesian school of thought is that probability represents a way to quantify a personal belief about an outcome, or as a *reasonable expectation*.  It is based on Bayes' Theorem, which we will be seeing shortly.  This is in contrast to the frequentist school of thought, for which the probability of an event occurring is the limit of its relative frequency over a large number of experiments or trials.\n",
    "\n",
    "### Notation and Formulas\n",
    "\n",
    "The first ingredient of probability is a _sample space_. The sample space is the set of outcomes that can possibly occur. For example, if we are thinking about rolling a die then we might have a sample space $\\Omega_{\\text{die}} = \\{1,2,3,4,5,6\\}$.\n",
    "\n",
    "_Events_ are subsets of the sample space; they're things that could happen. There are simple events like $A=\\text{you roll a 1}$, but we can think about more complex events that contain multiple outcomes from the sample space as well, like $B=\\text{you roll an even number}$. Note that each of these can be expressed explicitly as subsets of the sample space: $A=\\{1\\}$ and $B=\\{2,4,6\\}$.\n",
    "\n",
    "A probability is a function that takes events and gives back numbers. The number is always between 0 and 1, and it satisfies certain properties that we won't go into in detail here, but that you can read about [here](https://en.wikipedia.org/wiki/Probability_axioms).\n",
    "\n",
    "#### Mutually Exclusive Events\n",
    "\n",
    "We say that events $A$ and $B$ are _mutually exclusive_ if it would be impossible for them to both happen at the same time. An important rule of probability is that for mutually exclusive events, the probability that at least one of them happens is the sum of their probabilities.\n",
    "\n",
    "$$P(A\\cup B) = P(A) + P(B).$$\n",
    "\n",
    "Note that this is only true for mutually exclusive events. For events that could possibly both happen at the same time, we need to adjust the formula a bit:\n",
    "\n",
    "$$P(A\\cup B) = P(A) + P(B) - P(A\\cap B)$$\n",
    "\n",
    "#### Conditional Probability\n",
    "If we know that event $A$ has already occurred, how does it affect the probability that event $B$ will occur?  The *conditional probability* of $B$ given $A$, written $P(B\\,|\\, A)$, is given by the probability of both $A$ and $B$ happening, scaled by the probability of $A$ happening (since it's already happened):\n",
    "\n",
    "$$P(B\\,|\\, A) = \\frac{P(B\\cap A)}{P(A)} $$\n",
    "\n",
    "If, for example, we know that in a given city, the probability on any day of it being heavily overcast (H) is 0.45, and we know the probability that it is both heavily overcast AND raining (R) is 0.37, then the probability that it is raining on a given heavily overcast day is:\n",
    "\n",
    "$$ P(R\\,|\\,H) = \\frac{P(H\\cap R)}{P(H)} \\,=\\, \\frac{0.37}{0.45} \\,\\cong\\, 0.82. $$\n",
    "\n",
    "#### Independent Events\n",
    "\n",
    "We say that events $A$ and $B$ are independent if when you know that $A$ happened, that event tells you nothing about whether $B$ happened. We can write this in terms of conditional probability as follows:\n",
    "\n",
    "$$P(A|B) = P(A)$$\n",
    "\n",
    "It turns out that under the assumption that $A$ and $B$ are independent, we can come up with a nice formula for the probability $P(A\\cap B)$ that they both happen.\n",
    "\n",
    "$$\\begin{align}\n",
    "P(A \\cap B) &= P(A \\cap B) \\times \\frac{P(B)}{P(B)} \\\\\n",
    "&= \\frac{P(A \\cap B)}{P(B)} \\times {P(B)} \\\\\n",
    "&= P(A|B) \\times P(B) \\\\\n",
    "&= P(A) \\times P(B)\n",
    "\\end{align}$$\n",
    "\n",
    "The last line is by the independence assumption--without these events being independent we could not justify this last line, and the formula would be wrong! In general, it is not straightforward to come up with the probability of $P(A\\cap B)$ from $P(A)$ and $P(B)$ alone, so independence is a very strong assumption that makes computation a lot easier.\n",
    "\n",
    "#### Examples\n",
    "\n",
    "As an example, let's suppose we roll a 6-sided die and flip a coin at the same time. The probability that we either roll a 2 ($P(2) = 1/6$) **or** have heads show up ($P(H)=1/2$), we compute:\n",
    "\n",
    "$$ \\begin{align} \n",
    "P(2\\cup H) &= P(2) + P(H) - P(2 \\cap H) \\\\\n",
    "&= \\frac{1}{6} + \\frac{1}{2} - \\left(\\frac{1}{6} \\times \\frac{1}{2}\\right) \\\\\n",
    "&= \\frac{7}{12}\n",
    "\\end{align}$$ \n",
    "\n",
    "\n",
    "\n",
    "### Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem allows us to relate the conditional probability of two events in terms of inverse probability:\n",
    "\n",
    "$$  P(A\\,|\\,B) = \\frac{P(B\\,| \\, A)P(A)}{P(B)} $$\n",
    "\n",
    "The conditional probability of $A$ given $B$ is the ratio of the probability of $A$ to the probability of $B$, multiplied by the conditional probability of $B$ given $A$.  This will be important in the classification unit when we learn about Naive Bayes classification.\n",
    "\n",
    "#### Example: Spell Checker\n",
    "In text processing, a **language model** is a probability distribution over words. A very simple language model might look like this\n",
    "\n",
    "|Word|Probability|\n",
    "|----|----|\n",
    "|the| 0.057|\n",
    "|be|0.021|\n",
    "|I|0.001|\n",
    "|...|...|\n",
    "|there|0.0004|\n",
    "|...|...|\n",
    "|disintegrate|0.0000000029|\n",
    "|...|...|\n",
    "\n",
    "The simplest way to construct a probability model like this is to take a large corpus of text and count the appearances of each word.\n",
    "\n",
    "Bayesian reasoning can use language models like this to create things like spell checkers.\n",
    "\n",
    "Suppose the spell checker encounters `raim`. This is not a word in the English language. What might the typer have meant? Maybe `rain`? `rail`? `room`?\n",
    "\n",
    "The general aim of the Bayesian spell checker will be:\n",
    "\n",
    "1. Get word candidates\n",
    "2. For each candidate $c$, compute $P(\\text{Typer intended c}|\\text{Typer typed \"raim\"})$\n",
    "3. Whichever candidate maximizes this probability is the output of the Bayesian spell checker.\n",
    "\n",
    "To make things a little shorter and easier to deal with, let $\\theta$ represent the word that the typer meant to type, and $y$ represent the event that the typer typed \"raim\". So the second line becomes\n",
    "\n",
    "$$P(\\theta = c | y)$$\n",
    "\n",
    "How does _Bayesian modeling_ help? Use Bayes theorem to flip it around:\n",
    "\n",
    "$$P(\\theta = c | y) = \\frac{P(y|\\theta = c) P(\\theta = c)}{P(y)}$$\n",
    "\n",
    "Now, this expression may _look_ more complicated, but it's actually simpler to deal with.\n",
    "\n",
    "First of all, let's revisit the steps. We want to find the $c$ which maximizes the expression. But notice that if $c$ maximizes the right-hand side, it must be because it maximizes the numerator of the expression -- the denominator is not a function of $c$. So we can throw out the denominator, and now we are looking for $c$ which maximizes\n",
    "\n",
    "$$P(y|\\theta = c) P(\\theta = c)$$\n",
    "\n",
    "This number is known as the \"unnormalized likelihood\". Now, there are two parts to this expression, and each part we have a chance to actually compute. The second part, $P(\\theta = c)$ can be computed directly from the language model by looking up $c$, so that's done. All we need now is $P(y|\\theta = c)$. This is the probability that you _type_ y when you _mean_ $c$.\n",
    "\n",
    "We can create a simple model for this. We'll use the _edit distance_, which is a metric used in text processing to decide how close two words are. The edit distance is the smallest number of insertions, deletions, or substitutions that it takes to transform word $w_1$ into $w_2$. So the edit distance between \"cat\" and \"cat\" is zero, the edit distance between \"cat\" and \"car\" is 1, the edit distance between \"cat\" and \"cars\" is 2, and so on.\n",
    "\n",
    "Assume, as a crude model of typing, that the probability of typing $y$ when you mean $c$ is given by the formula\n",
    "\n",
    "$$P(y|\\theta = c) = 0.98 \\times 0.02^{\\text{edit(y,c)}}$$\n",
    "\n",
    "This is much too crude to use in practice, but it seems to work alright for our purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LwHIHkcqJ1C"
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "def type_prob(intended, typed):\n",
    "    return 0.98 * (0.02 ** edit_distance(intended, typed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZvs2Fi4qJ1E",
    "outputId": "6fd4f75d-c600-4706-e79d-2299a3658d30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_prob(intended=\"the\", typed=\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YcMPeRqqJ1H",
    "outputId": "7a6f4df1-4b0a-4c1d-81df-03b6f70e1f58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0196"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_prob(intended=\"cars\", typed = \"cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQz_gNQiqJ1J",
    "outputId": "d203f4b4-57c9-4217-d3cf-efe27c6dd606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.840000000000001e-06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_prob(intended=\"Yes\", typed=\"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9-pOiw7qJ1L"
   },
   "source": [
    "Below is a sample language model. Each word has some probability associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnjx7nBpqJ1M"
   },
   "outputs": [],
   "source": [
    "language_model = {\"the\": 0.053, \"tar\": 0.000039, \"rain\": 0.000045, \"rail\": 0.0000021, \"room\": 0.000060}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mv68YUu9qJ1O"
   },
   "source": [
    "### Exercise:\n",
    "Use each of the words in the language model as candidate words for the error correction. Use the probabilities from `language_model` and `type_prob`. Compute the unnormalized likelihood for each word. What should the word \"raim\" be corrected to? What about \"roim\"? What about \"tfr\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suggested solution\n",
    "def word_correct(typed_wrd):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suggested solution\n",
    "def word_correct(typed_wrd):\n",
    "    maxprob=0\n",
    "    likelyword=''\n",
    "    \n",
    "    for each_wrd, each_prob in language_model.items():\n",
    "        p_theta_c = type_prob(each_wrd, typed_wrd)\n",
    "        prob = p_theta_c * each_prob\n",
    "        if prob>maxprob:\n",
    "            likelyword = each_wrd\n",
    "            maxprob=prob\n",
    "    return likelyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qn-cC-nTqJ1R",
    "outputId": "fece9186-ada6-4e33-fe0b-d5571c855698"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rain'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_correct(\"raim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFb64JGUqJ1U",
    "outputId": "011c70c2-5686-499b-cf80-3d38e7c7225b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'room'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_correct(\"raom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXo5_Qn1qJ1W",
    "outputId": "ecd02824-3fd0-4fd7-ad77-753bd155984d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tar'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_correct(\"tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cD7w1tZbqJ1Z",
    "outputId": "018a3e34-7bdf-4215-f916-7fb8423f711e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_correct(\"tfr\")  # note this has edit distance closer to \"tar\" than \"the\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIXl_6dXqJ1c"
   },
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STMNI7ZKqJ1d"
   },
   "source": [
    "Hypothesis testing is a fundamental part of _frequentist_ statistics. Frequentists differ from Bayesians in their concept of what probability means, and sometimes Bayesians and Frequentists disagree on the best way to do things. But we are neither pure Bayesians, nor pure Frequentists, but Data Scientists, and the Frequentist hypothesis testing framework is still the most common way to analyze data in science, social sciences, economics, and applied work such as A/B testing, so it's important to understand.\n",
    "\n",
    "Hypothesis testing deals with determining whether your data provides _statistically significant_ evidence for or against some theory or hypothesis. Let's start with an example.\n",
    "\n",
    "You flip a coin five times, and it comes up heads on each flip. We'll use hypothesis testing to determine whether this is statistically significant evidence that the coin is biased.\n",
    "\n",
    "Hypothesis testing begins by choosing a **null hypothesis**. The null hypothesis, often denoted by $H_0$, should be essentially the opposite of what it is you suspect or are trying to prove. It is \"null\" because it usually corresponds to the idea of \"no effect\", that there is \"nothing\" there.\n",
    "\n",
    "What would be the null hypothesis in this experiment?\n",
    "\n",
    "Under the null hypothesis, we can now answer the following fundamental question:\n",
    "\n",
    "**_If_ the null hypothesis is true, what would be the probability of our dataset?**\n",
    "\n",
    "What would be the probability of flipping five heads in a row if the null hypothesis is true? \n",
    "Use the below block to do the math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QA_4DFmqqJ1e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Yf0HJ7zqJ1g"
   },
   "source": [
    "This number is called a **p-value**. The **p-value**  (or calculated probability) is the probability of finding the observed, or more extreme, results when the null hypothesis ($H_{0}$) of a study question is true  (the definition of extreme depends on how the hypothesis is being tested). P is also described in terms of rejecting $H_{0}$ when it is actually true, however, it is not a direct probability of this state. If the p-value is large, then the result we observed would be relatively common if the null hypothesis were true. In that case, we conclude that this data is not significant evidence against the null hypothesis. On the other hand, if the p-value is very small, then if the null hypothesis were true, our result would be very unlikely. In this case, we **reject the null hypothesis** and declare that we have statistically significant evidence against the null hypothesis.\n",
    "\n",
    "**Do we accept or reject the null hypothesis for our coin flips? Are 5 flips enough to be statistically significant?**\n",
    "\n",
    "#### Significance level\n",
    "\n",
    "The typical frequentist hypothesis testing approach starts by specifying a significance level below which we will reject the null hypothesis, and this is often denoted by $\\alpha$, and a typical number is $\\alpha=0.05$. Thus, when we see p-values below 0.05, we usually declare that we have statistically significant results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znIubfkFMvEJ"
   },
   "source": [
    "### Null Hypothesis\n",
    "\n",
    "Given a data set, one often wants to test if there is an intrinsic relationship between subsets of the data, or to use the data to attempt to validate a theory.  One statistical approach to accomplishing this is the use of a **null hypothesis**, often denoted $H_0$. The idea is similar to \"proof by contradiction\" in mathematics: \n",
    "1. Denote the hypothesis we wish to validate $H_1$, the **alternative hypothesis**.\n",
    "2. Suppose that $H_0$ is true: there is no intrinsic relationship in the data that the results occurred purely by chance.\n",
    "3. Using a statistical test, compute if $H_0$ is incredibly unlikely.  \n",
    "4. If so, reject $H_0$.  Else, reject $H_1$.\n",
    "\n",
    "In the case where we do not reject the null hypothesis, we would have to reformulate our initial hypothesis for future testing (or discard it entirely).  \n",
    "\n",
    "As an example, suppose we had measurements of ancient Egyptian skulls through archaeological finds.  One hypothesis we may wish to test is \"the breadth of skulls in humans increases over time\", using current average skull breadth measurements as the testing criterion.  \n",
    "\n",
    "The null hypothesis would be that the skull breadths *do not* increase over time (i.e. the average of the measurements in the sample data would be greater than or equal to the current skull size average).  If we had a statistical test that we could apply to show that the null hypothesis is incredibly unlikely considering the skull data we have, then we could reject the null hypothesis in favor of our hypothesis about increasing skull breadth over time.  \n",
    "\n",
    "But how do we test and decide what's unlikely or not?  One method is using p-values as metrics for statistical tests.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHXK5OOPMvEJ"
   },
   "source": [
    "### P-Values\n",
    "\n",
    "Suppose we have an observation (data set), a null hypothesis $H_0$, and an alternative hypothesis $H_1$.  If we presume $H_0$ to be true, then the **p-value** is the probability that we would obtain results which are at least as extreme as the observed data.  If the p-value is very low (i.e. lower than a specified significance level), this tells us that $H_0$ may not be sufficient to explain the data that we have.  This allows us to reject the null hypothesis and accept the alternative hypothesis.  \n",
    "\n",
    "Significance levels for p-values are chosen often by convention but are arbitrary.  Often, the choice of p < 0.05 is used.  There is controversy and misunderstanding surrounding p-values. In particular, it should be stressed that p-values should not be the sole deciding factor in inference, but should be used in conjunction with context about the data.  Ronald Wasserstein & Nicole Lazar note in their paper \"The ASA's Statement on p-Values: Context, Process, and Purpose\" (see link below), that:\n",
    "\n",
    ">Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, yes-no decisions, but this does not mean that p-values alone can ensure that a decision is correct or incorrect. The widespread use of  statistical significance  (generally interpreted as p  0.05) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.\n",
    "\n",
    "The key thing to remember is that p-values are computed under the assumption that the null hypothesis is true, and tell you how likely it would be to observe values more extreme than what is in the data set.  As a result, it tells you nothing about the probability of whether either hypothesis is *true* or not.    \n",
    "\n",
    "Further reading can be found here:\n",
    "\n",
    "https://www.uv.es/sestio/TechRep/tr14-03.pdf<br>\n",
    "https://en.wikipedia.org/wiki/Misunderstandings_of_p-values<br>\n",
    "http://amstat.tandfonline.com/doi/full/10.1080/00031305.2016.1154108\n",
    "\n",
    "If we've decided to move forward with using p-values, confident in our knowledge of what they are and are not, the question arises:  how do we compute them?  This is generally accomplished by selecting a particular test for the hypothesis, computing a *test statistic*, and using its value with the *sampling distribution* to obtain the p-value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okTSmJUxMvEJ"
   },
   "source": [
    "### Test Statistics\n",
    "\n",
    "To help us determine whether or not to reject the null hypothesis, we need to choose a statistical test to perform based on the properties of the data, that will quantify a way to distinguish the hypotheses.  Each test specifies a **test statistic**: a single quantity that in some way summarizes important aspects of the data set we're interested in (mean, correlation coefficient, more complicated computations, etc.) which will be used with the observed data to evaluate the likelihood of the null hypothesis.  We can make our method in the null hypothesis section above a little more precise:\n",
    "\n",
    "1. State the null and alternative hypotheses.\n",
    "2. Decide on a level of significance to compare the p-value to.\n",
    "3. Choose a test which suits the kind of data.\n",
    "4. Compute the value of the test statistic for the data set.\n",
    "5. Determine the p-value from the test statistic using the sampling distribution.\n",
    "6. Decide whether or not to reject the null hypothesis by checking the p-value against the level of significance.\n",
    "\n",
    "There are different categories of tests, depending on the type of data we have, which will change the form of the test statistic.  Two main types are:\n",
    "\n",
    "* **One-sample tests**: are used when comparing data to a known population or value.  \n",
    "* **Two-sample tests**: are used when comparing two different data sets. \n",
    "\n",
    "We'll have a closer look at a few examples shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkYMSVlNMvEL"
   },
   "source": [
    "### Sampling Distribution\n",
    "\n",
    "Suppose $x_1,x_2,\\ldots,x_n$ are observed values from a data set. We can define the **sample distribution function** $F_n(x)$, in the following way:\n",
    "1. The argument, $x$, can be any real number.\n",
    "2. The function outputs the proportion of numbers in our data set that are $\\leqslant\\, x$. \n",
    "\n",
    "i.e. if, in our data set, there are exactly $k$ values which are less than or equal to x, then $F_n(x) = \\frac{k}{n}$.  \n",
    "\n",
    "For the purposes of statistical testing, we are concerned with computing the sample distribution for the *test statistic* for the test we're performing, given the size of our data set.  This will give us the proportion of values less than or equal to the value we computed, which will let us figure out the p-value, (i.e. the probability of observing something more extreme than what we did).\n",
    "\n",
    "Actually, computing sample distributions can be fairly labor-intensive; before the advent of computer programs capable of computing these numbers on demand, statisticians would have to reference values in very large tables.  We'll be letting Python do the work for us, though.  Let's have a look at different kinds of statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSxalBQfMvEL"
   },
   "source": [
    "### ShapiroWilk test\n",
    "\n",
    "The Shapiro-Wilk test is a way to determine if a given data set is Gaussian.  In the set-up of the test, the null hypothesis is that the given data set _**is**_ normally distributed.  Once we choose a level of significance for our test, we can run the the test and compute both the test statistic and the p-value.  If, for example, we choose our significance level to be 0.05, and the p-value we compute is 0.025 for a given data set $X$, then we reject the null hypothesis that $X$ is normally distributed.  If, however, we compute a p-value of 0.12, then we cannot reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWaKCMSAMvEM"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1_kFNQgla_khqC7y4ULySMw9LbMncsl57\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Az5DjQHpMvEM"
   },
   "source": [
    "For a given data set $X = \\{x_1,\\ldots,x_n\\}$, the Shapiro-Wilk test statistic has the form:\n",
    "\n",
    "$$ W = \\frac{\\left(\\sum_{i=1}^ka_i(x_{(n-i+1)}-x_{(i)}) \\right)^2}{\\sum_{i=1}^n(x_i - \\mu_X)}, $$\n",
    "\n",
    "where $x_{(j)}$ denotes the $j^{th}$ element of $X$ when re-arranging into ascending order, $\\mu_X$ is the mean of $X$, the coefficients $a_i$ depend on $n$ and are computed via a matrix equation, and $k = \\bigl\\lfloor \\frac{n}{2} \\bigr\\rfloor$, which is $\\frac{n}{2}$ rounded down the nearest integer.\n",
    "\n",
    "We can use the SciPy function `stats.shapiro(x)` to compute the Shapiro-Wilk test for a given data set `x`.  The function will output two numbers, `(W,p)`, which are the test-statistic and p-value, respectively.  Let's compare two data sets, and choose ahead of time our significance level to be $0.01$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4D11PeD5MvEN"
   },
   "outputs": [],
   "source": [
    "x1 = [19, 18, 16, 14, 11,  0,  8, 12, 17, 18, 10,  7, 16, 18, 15, 12,  0, 4,  4, 11, 15,  4, 12, 13,  8, 18, \n",
    "      11, 18,  3,  5, 18, 14, 12,  3, 15, 18,  2, 18,  2, 18, 12,  7,  2,  7,  2, 17,  9,  9,  4,  6, 69, 97, \n",
    "      84, 90, 80, 80, 74, 79, 48, 85, 48, 94, 50, 60, 70, 59, 83, 64, 79, 68, 96, 86, 76, 87, 43, 96, 77, 70, \n",
    "      64, 69, 70, 40, 78, 40,  67, 50, 82, 96, 48, 50, 97, 78, 42, 75, 60, 79, 65, 83, 50, 50]\n",
    "# obtained via concatenating two np.random.randint(a,b,50), one from 0 to 30, and one from 50 to 100.\n",
    "\n",
    "x2 = [  16.50910448,  22.39398283,  22.27626366,  16.22325598, 21.87551527,  21.40104677,  18.06070508,  17.48751555,\n",
    "        15.03445503,  19.79045477,  15.3734691 ,  21.06006474, 16.24847507,  25.90433196,  21.00225332,  21.84069789,\n",
    "        18.16321542,  19.83138415,  14.89816334,  18.22877618, 16.91501954,  17.98657684,  20.45551657,  18.34817168,\n",
    "        20.85156526,  14.43832657,  23.00033636,  19.07868946, 16.34545215,  19.29270657,  22.65088714,  21.35318661,\n",
    "        19.76075478,  21.24389901,  15.70178397,  23.09017102, 16.31758063,  17.03078011,  20.64382268,  22.77800154,\n",
    "        21.67719434,  20.52426192,  12.64210407,  12.19122028, 20.91931133,  17.20447393,  18.35246361,  17.67549573,\n",
    "        18.63156913,  14.09206448,  19.26118913,  11.50262005, 23.70571152,  17.15269872,  23.01609265,  21.94062937,\n",
    "        21.01816282,  18.66123268,  18.16277525,  23.70817879, 27.38365385,  21.46336741,  21.42017973,  21.5376097 ,\n",
    "        15.1677562 ,  19.63875956,  17.87046269,  23.89264974, 26.92608041,  22.40678648,  20.26913699,  19.77450803,\n",
    "        19.61472674,  21.81003095,  22.02735034,  21.53584979, 19.22672501,  22.23608912,  18.96711669,  17.13995069,\n",
    "        21.41165054,  16.85484758,  20.87604705,  18.47511586, 14.79669234,  21.72165664,  17.11637749,  25.31159641,\n",
    "        20.55319247,  16.31414202,  16.14344031,  20.64910554, 17.98645468,  16.30465569,  16.93656026,  18.25318075,\n",
    "        18.54833335,  15.75328812,  21.74905835,  20.26089833]\n",
    "# obtained via np.random.normal(loc=20,scale=3,size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JC8xSK2IMvEP"
   },
   "source": [
    "In particular, we have good reason to believe that `x2` is normally distributed, since it was generated via a normal random sampling; the set `x1`, however, was generated via uniform random sampling across two different ranges, so there's no particular reason to think this set will be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpUTDNVaMvER"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8689814209938049, 6.37875317011094e-08)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwKhIZA8MvES"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9894847273826599, 0.623079240322113)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ji0t2YM7MvEV"
   },
   "source": [
    "1. For `x1`, the p-value is $\\cong 0.0000000638$, which is certainly less than our chosen significance level of $0.01$.  Hence, we reject the null hypothesis that `x1` is normally distributed.  \n",
    "2. For `x2`, the p-value is $\\cong 0.623$, which is not less than $0.01$, meaning we cannot reject the null hypothesis that `x2` is normally distributed.\n",
    "\n",
    "This lines up with our expectations, given the contrived nature of the example.\n",
    "\n",
    "Testing whether a data set is normally distributed can potentially give us another way to deal with outliers:  the **z-score** of an element $x$ of a data set $X$ with mean $\\mu$ and standard deviation $\\sigma$ is given by\n",
    "$$  z = \\frac{x-\\mu}{\\sigma} $$\n",
    "This is a measure of how many standard deviations from the mean the element $x$ is.  Since $99.7\\%$ of data is contained within three standard deviations of the mean for a normally distributed set, this means that if a data point has a z-score of more than three (or less than -3), then we can potentially discard it as an outlier. \n",
    "\n",
    "Consider the following data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIG1LIzRMvEV"
   },
   "outputs": [],
   "source": [
    "n = [   26.35022317,  20.75227751,  23.47751465,  22.87726524, 22.18087948,  23.8744957 ,  22.84644217,  23.75790925,\n",
    "        18.10016637,  32.96650641,  26.19575661,  26.06633301, 22.63250235,  28.23314674,  26.92962223,  18.37144332,\n",
    "        24.28580894,  28.73297662,  19.73941276,  24.18843525, 26.83554143,  23.56251076,  25.14174836,  28.56764978,\n",
    "        24.35712616,  22.97048562,  26.88372203,  10.21119535, 29.87102246,  22.79502915,  26.94472247,  29.43139378,\n",
    "        27.72083063,  28.88420645,  24.34621529,  27.13172742, 24.2544851 ,  29.31440951,  23.32003235,  23.40796604,\n",
    "        27.47217412,  21.95813955,  21.64514648,  25.86996744, 19.56790511,  23.9574127 ,  19.199265  ,  26.52683638,\n",
    "        27.9121632 ,  27.07325111]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xq_qHIDUMvEY"
   },
   "source": [
    "Applying the Shapiro-Wilk test with a significance level of 0.01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xzyf7HllMvEY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9403377175331116, 0.0138937309384346)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhcX6Ns6MvEb"
   },
   "source": [
    "The p-value is $\\cong 0.014 > 0.01$, so we do not reject the null hypothesis that `n` is normally distributed.  We can compute the z-scores of the elements of `n` with `starts.zscore(n)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89mwqPrqMvEc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46619523, -1.01968619, -0.29631739, -0.4556436 , -0.6404876 ,\n",
       "       -0.19094539, -0.46382507, -0.22189132, -1.72364492,  2.22237739,\n",
       "        0.42519465,  0.39084131, -0.52061183,  0.96598592,  0.61998706,\n",
       "       -1.65163897, -0.08176914,  1.09865744, -1.28853427, -0.10761536,\n",
       "        0.59501487, -0.27375659,  0.14542572,  1.05477418, -0.06283917,\n",
       "       -0.4308998 ,  0.60780361, -3.81764085,  1.40073275, -0.4774718 ,\n",
       "        0.62399516,  1.28404064,  0.83000014,  1.13879888, -0.06573528,\n",
       "        0.67363251, -0.09008353,  1.25298911, -0.33811845, -0.31477791,\n",
       "        0.76399842, -0.6996102 , -0.782689  ,  0.33871934, -1.33405812,\n",
       "       -0.16893645, -1.43190749,  0.51307426,  0.88078619,  0.65811095])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.zscore(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hgjgF4MMvEe"
   },
   "source": [
    "We can find where the absolute z-score is greater than 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_t6dpa0MvEf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([27]),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(abs(stats.zscore(n))>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54Tjeps6MvEh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.21119535"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RTVzl3NNMvEj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.291595308643904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(n) - 3*np.std(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Adm1Mg9JMvEl"
   },
   "source": [
    "Hence, the element 10.21119535 is more than 3 standard deviations away from the mean ($\\mu -3\\sigma \\cong 13.29$), and thus we can potentially discard it as an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akJzxq3hMvEm"
   },
   "source": [
    "### Chi-squared Test\n",
    "\n",
    "The chi-squared ($\\chi^2$) test arises from the chi-squared distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4bemRtY1MvEm"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1NGfSbweetyDyPi9RGd6S06GUNV14dWfD\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I20cb2RQMvEo"
   },
   "source": [
    "This distribution is related to randomly sampling from a number of normal distributions, where the $k$ values represent the degrees of freedom in the sampling.  Chi-squared tests are specifically for categorical data (not numerical, but qualitative data, like names, etc.), and can help determine a number of things, including whether the frequency of observations in a data set diverges from a theoretical distribution of frequencies, and whether two data sets are independent of one another. The chi-squared test statistic has the following form:\n",
    "\n",
    "$$ Q = \\sum_{i=1}^k\\frac{(N_i - n{p_i}^0)^2}{n{p_i}^0}  $$\n",
    "\n",
    "Where $N_i$ is the number of observations in the data that is of type $i$ (for whatever categories of data we have), ${np_i}^0$ is the *expected* number of observations that are of type $i$, and $k$ is the number of different types of data we have in our set.  \n",
    "\n",
    "Here is an example of a problem we could apply this test statistic to:  AA Publishing prints comic books. It claims that 30% of the comic issues are special variant covers, 65% are normal covers, and 5% are holographic covers.  If we took a random sample of 100 comics that has 50 variant covers, 40 normal covers, and 10 holographic covers, is this consistent with the company's claim? \n",
    "\n",
    "To test this, we will use SciPy's `stats.chisquare()` function, which tests the null hypothesis that the observed data has the given expected frequencies.  For problems like the one here, the function takes two arguments:  a collection of sample observations, and the expected observations.  The function outputs two numbers, the chi-squared test statistic value, and the computed p-value.  Let us decide on a significance level of $0.05$ for this test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5O-71EiMvEo"
   },
   "outputs": [],
   "source": [
    "AAclaims = [30,65,5]\n",
    "Observed = [50,40,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCr9H8q9MvEr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=27.94871794871795, pvalue=8.531256690329268e-07)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(Observed,AAclaims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKBO5tlfMvEt"
   },
   "source": [
    "So the p-value we computed is $\\cong 0.00000085$, which is certainly less than the chosen significance level of $0.05$.  Thus, we must reject the null hypothesis that the observed data has the frequencies claimed by the publishing company.  If we, instead, had randomly sampled 28 variant covers, 63 regular covers, and 9 holographic covers, we'd compute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQTRbG0YMvEt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=3.3948717948717952, pvalue=0.18315254439634107)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Observed = [28,63,9]\n",
    "AAclaims = [30,65,5]\n",
    "stats.chisquare(Observed,AAclaims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBr1AllMMvEw"
   },
   "source": [
    "The p-value of $\\cong 0.18$ is bigger than our significance level of $0.05$, so we could not reject the null hypothesis that the observed data has the frequencies claimed by AA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2cJ8QMbMvEw"
   },
   "source": [
    "### Student's t-Test\n",
    "\n",
    "The t-test comes from the t-distribution; the red and green graphs show the t-distribution for one and two degrees of freedom, with the blue graph shows the Gaussian distribution for comparison:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qaQxNS0oMvEx"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1kQmmkvGbEj6iZpffA2UusJ8MI71urjVO\" height=\"300\" width=\"300\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2MtaLb7MvEx"
   },
   "source": [
    "The t-test is used for comparing the mean of data sets:  either comparing the mean of a single data set to a given value, or comparing the means of two data sets.  The (one-sample) t-statistic has the form:\n",
    "\n",
    "$$ t = \\frac{\\overline{x} - \\mu}{\\left(s\\,\\big/ \\sqrt{n}\\right)}$$\n",
    "\n",
    "where $\\overline{x}$ is the mean of the sample (the data set we have), $\\mu$ is the value we are testing against, $s$ is the standard deviation of the sample, and $n$ is the size of the sample.  There are a number of assumptions underlying the t-test, but one of the major ones is that the populations being compared are both Gaussian.  \n",
    "\n",
    "We can use the SciPy function `stats.ttest_1samp()` for a one-sample t-test, which takes a set of observations and a given mean as arguments, and outputs the t-statistic value and the p-value.  The null hypothesis being tested is that the mean of a given data set is equal to the specified population mean.\n",
    "\n",
    "An example of a problem we could apply the test to:  suppose we had a sample of (systolic) blood pressure measurements from 50 first-year EMTs at rest.  Suppose further that we have data for the average resting blood pressure for the general populace. Are the observed data for the EMT blood pressures consistent with the general populace's average?  Let's choose a significance level of $0.05$ for this test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOH5AgHjMvEx"
   },
   "outputs": [],
   "source": [
    "EMT_bp = [106, 106, 113, 110, 114, 136, 125, 114, 134, 116, 113, 122, 144, 141, 102, 107, 140, 139, 101, 103, \n",
    "          114, 113, 109, 133, 139, 137, 122, 121, 108, 110, 135, 111, 115, 105, 112, 109, 139, 119, 133, 132, \n",
    "          120, 109, 141, 102, 130, 101, 134, 143, 122, 129]\n",
    "mean_sbp = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXHilOMCMvE0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=0.3461821343694726, pvalue=0.7306879364583656)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_1samp(EMT_bp,mean_sbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8jZTjwmMvE2"
   },
   "source": [
    "The p-value for this test was $\\cong 0.73$, which is *much* greater than the significance level of $0.05$ we chose.  This means that we cannot reject the null hypothesis, and so can conclude that the systolic blood pressures of the sampled EMTs is fairly consistent with the general populace's average.  For a different set of blood pressures, however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmkXG1UDMvE2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=10.42986165960409, pvalue=4.886680129863528e-14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMT_bp2 = [123, 129, 127, 124, 144, 130, 141, 126, 131, 121, 128, 139, 126, 142, 124, 129, 139, 141, 144, 132, \n",
    "           122, 121, 130, 123, 115, 130, 123, 124, 129, 129, 124, 134, 139, 124, 131, 121, 133, 140, 137, 142, \n",
    "           133, 140, 142, 133, 130, 133, 135, 119, 133, 137]\n",
    "\n",
    "stats.ttest_1samp(EMT_bp2,mean_sbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ol5f5GESMvE5"
   },
   "source": [
    "The p-value is $\\cong 0.000000000000049$, which is much less than the significance level of $0.05$.  Thus, we can reject the null hypothesis that this particular set of EMTs' blood pressure is consistent with the general populace's average blood pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGkUBETKqJ1g"
   },
   "source": [
    "### Statistical Tests for Differences in Means\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0cfVdx6qJ1h"
   },
   "source": [
    "#### One Sample\n",
    "\n",
    "Suppose instead of flipping a coin five times, we flip a coin 300 times, and it comes up heads 198 times. How can we use statistical testing to test whether the coin is biased?\n",
    "\n",
    "Encode the coin flips as 0's and 1's, with 1 being heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68SqIb1oqJ1i"
   },
   "outputs": [],
   "source": [
    "flips = [1,1,1,1,1,1,1,1,1,0,1,0,1,0,0,1,0,\n",
    "         1,0,1,1,0,1,0,0,1,1,1,1,1,1,0,1,0,\n",
    "         1,1,1,0,1,1,1,1,1,1,0,1,1,0,1,1,1,\n",
    "         0,1,0,1,1,1,0,1,0,1,1,0,1,1,1,1,0,\n",
    "         1,1,0,1,0,1,1,0,0,1,1,1,1,1,1,1,1,\n",
    "         0,1,1,0,1,0,0,1,1,1,1,1,0,1,1,1,0,\n",
    "         0,0,1,1,1,0,0,0,1,0,1,1,0,1,0,1,1,\n",
    "         0,0,1,0,0,1,1,0,0,1,1,1,1,1,0,1,1,\n",
    "         0,0,1,1,1,1,0,0,1,0,1,0,1,1,1,1,1,\n",
    "         0,0,0,1,1,1,0,0,1,0,0,0,1,1,1,1,1,\n",
    "         0,1,1,0,0,1,1,0,1,1,1,0,1,1,0,0,0,\n",
    "         0,1,1,0,1,0,0,1,0,1,0,1,1,0,1,1,1,\n",
    "         1,0,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,\n",
    "         0,1,0,1,1,1,0,1,1,0,0,1,0,1,1,0,0,\n",
    "         1,0,1,1,1,1,1,0,1,0,0,1,1,0,1,1,1,\n",
    "         1,1,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,\n",
    "         1,0,1,0,1,0,0,1,1,1,0,0,1,1,1,1,1,\n",
    "         1,1,1,0,0,0,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3u6ToY5CqJ1j"
   },
   "source": [
    "In principle, we can use the same approach that we used above. What would be the null hypothesis?\n",
    "\n",
    "Under the null hypothesis, we could compute a p-value as\n",
    "\n",
    "$$P(\\text{Heads Count} \\geq 198) = \\sum_{k=198}^{300}\\left( {300 \\choose k}\\times \\frac{1}{2^{300}} \\right)$$\n",
    "\n",
    "This is a fairly difficult computation to perform. Thankfully, there's an easier way.\n",
    "\n",
    "The null hypothesis, as above, is that the true probability of heads is $\\frac{1}{2}$. Under this null hypothesis, **the expected value of the sample mean of the coin flip sequence is ** $\\frac{1}{2}$.\n",
    "\n",
    "There is a very important theorem in statistics called the [Central Limit Theorem ](https://en.wikipedia.org/wiki/Central_limit_theorem) that implies that **sample means are normally distributed**. The math required to prove this is beyond the scope of this course, but the upshot of this is that we always have a statistical test that we can use to test whether sample means are equal to some specific number.\n",
    "\n",
    "The test is called a t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cNCHIQsqJ1j",
    "outputId": "2e086c7c-a68d-4bd8-95e2-d652a10e0522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=5.840420955209167, pvalue=1.3571704413357249e-08)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform a one sample t-test on the coin data\n",
    "from scipy import stats\n",
    "stats.ttest_1samp(a=flips, popmean=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BEG798AQqJ1l"
   },
   "source": [
    "The p-value is well below .05 or even .001, so we reject the null hypothesis of a fair coin and conclude that there is statistically significant evidence of bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcBBTLUjqJ1m"
   },
   "source": [
    "### Evaluating an A/B Test with Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hu6Wmbx5qJ1m",
    "outputId": "4401acd8-21ed-4e5a-d411-a0b77bed5891"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>time_on_page</th>\n",
       "      <th>browser</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>1.748084</td>\n",
       "      <td>Safari</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>5.947352</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>2.007091</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.633244</td>\n",
       "      <td>Safari</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.560507</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       group  time_on_page  browser  click\n",
       "0    Control      1.748084   Safari  False\n",
       "1  Treatment      5.947352  Firefox   True\n",
       "2    Control      2.007091   Chrome  False\n",
       "3  Treatment      1.633244   Safari   True\n",
       "4    Control      0.560507   Chrome   True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abtest = pd.read_csv('data/abtest.csv')\n",
    "abtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dATJtUxRqJ1o",
    "outputId": "6aa6b86e-0735-40f9-abfe-04e58624ab63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_on_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.158508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.962611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.105017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.473013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.948161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.989886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.474860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_on_page\n",
       "count    300.000000\n",
       "mean       5.158508\n",
       "std        5.962611\n",
       "min        0.105017\n",
       "25%        1.473013\n",
       "50%        2.948161\n",
       "75%        5.989886\n",
       "max       30.474860"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abtest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGD2b2naqJ1q"
   },
   "source": [
    "A/B tests are a modern business take on the idea of a [Randomized Controlled Trial](https://en.wikipedia.org/wiki/Randomized_experiment). RCTs are experiments where participants are randomly assigned either a `Control` or a `Treatment`. For instance, in clinical trials, the Control is usually some kind of placebo pill, whereas the Treatment is the real drug. A/B testing is used widely in UX/UI design to measure the impact of design tweaks.\n",
    "\n",
    "The beauty of an A/B test is that it allows us to jump from the observation that things are _correlated_ with the treatment variable to the conclusion that the treatment is **causing** an effect. This is very powerful, and something that we can't always do without the benefit of randomization.\n",
    "\n",
    "The dataset above gives the results of an A/B test. 300 participants were randomly selected into either a _Control_ group or a _Treatment_ group. The Control group was shown an existing landing page, and the Treatment group was shown a redesigned version. The intent of the experiment is to determine whether the redesign encouraged people to view the page for longer. The time spent on the page is given.\n",
    "\n",
    "**How should we evaluate the experiment?**\n",
    "- What metric we use to compare?\n",
    "- What is the null hypothesis?\n",
    "- What is the alternative hypothesis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqu5aLlUqJ1r"
   },
   "source": [
    "The most common approach is to compare means between the two groups. Recall that when we are comparing means, we use a t-test. In this case, we use a _two sample_ t-test, which is implemented by the function `stats.ttest_ind`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC8QRrFTqJ1u",
    "outputId": "b7934b23-5b23-44fc-9fb3-4f98d8eae126"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnAR1tThqJ1w"
   },
   "source": [
    "What do we conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wqx67zOqJ1w"
   },
   "source": [
    "#### Testing A/B test inclusion criteria\n",
    "\n",
    "Experiments allow us to make statistically rigorous causal inferences, but they do not allow us to say anything _for certain_. It is _possible_ that, for instance, by some crazy fluke, all the people who ended up in the treatment group happened to just have very long attention spans, and would have stayed longer on the page regardless of the redesign.\n",
    "\n",
    "The laws of probability imply that this would be very unlikely. As long as selection into the treatment group is **random**, then there should be just as many long-attention-span people in the treatment group as there are in the control group. The larger our sample size, the more confident we can be about this.\n",
    "\n",
    "One way that we reassure ourselves that there are no hidden correlations on unobserved variables with the selection is to check that other observed variables are uncorrelated with the selection. If the observed variables are uncorrelated with the selection, it becomes that much easier to believe that unobserved variables are as well.\n",
    "\n",
    "In our experiment, we also observe which browser the user used to view the landing page. As long as selection is random, this should be uncorrelated with the treatment. We can examine this using the `pd.crosstab` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dZFEae6qJ1x",
    "outputId": "ab50be8a-172f-4bce-a833-32d9cf7a6ca5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>group</th>\n",
       "      <th>Control</th>\n",
       "      <th>Treatment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chrome</th>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edge</th>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Firefox</th>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Safari</th>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group    Control  Treatment\n",
       "browser                    \n",
       "Chrome        73         71\n",
       "Edge          17         19\n",
       "Firefox       26         34\n",
       "Safari        26         34"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab = pd.crosstab(abtest['browser'], abtest['group'])\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUKuCA3GqJ12"
   },
   "source": [
    "We can see that the treatment group had more Chrome users than the control group, whereas the Control group had more Firefox users. This is, of course, not unexpected: if selection is random then is would be very unlikely to have the same number of each browser in each group. Nonetheless, we would like to test whether there is a _statistically significant_ difference between the distributions of browsers across the treatment variable. If there is, then our ability to make a causal inference about the treatment could be impacted.\n",
    "\n",
    "- Null hypotheses: the distribution of browsers is statistically independent of treatment status\n",
    "- Alternative hypothesis: the distribution of browsers is dependent on treatment status\n",
    "\n",
    "The table in `crosstab` is known as a _contingency table_. There is a test known as the chi-squared test which tests this exact hull hypothesis for contingency tables. We run the test below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XI5h2GdsqJ13",
    "outputId": "fe5f3e68-ea76-4846-b7d0-cdfae0dd8641"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.422936352290961, 0.7001672398372076, 3, array([[68.16, 75.84],\n",
       "        [17.04, 18.96],\n",
       "        [28.4 , 31.6 ],\n",
       "        [28.4 , 31.6 ]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2M2gLw0KqJ15"
   },
   "source": [
    "**Read the docstring (use the shift-tab trick) of stats.chi2_contingency to interpret this output. Do we accept or reject the null hypothesis?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqeI5GypMvE5"
   },
   "source": [
    "### Type I/II Errors\n",
    "\n",
    "We've set up our null hypothesis, chosen our test, selected the p-value threshold, run the test, and chosen whether or not to reject the null hypothesis.  It's quite possible that our choice was correct, but it's also possible that it was not.  We can categorize incorrect choices into the following error types:\n",
    "\n",
    "1. **Type I Error**: the null hypothesis was true, but we rejected it. (False positive.)\n",
    "2. **Type II Error**: the null hypothesis was false, but we did not reject it. (False negative.)\n",
    "\n",
    "One way to think about this is Type I errors are risky, you banked on the existence of something that wasn't there; Type II errors are timid, and you played it safe assuming nothing was there.  We can sum up the possibilities for a given null hypothesis $H_0$ with the following table:\n",
    "\n",
    "|   .  |      $H_0$ False        |    $H_0$ True           |\n",
    "|----:|:-----------------------:|:-----------------------:|\n",
    "| **Reject** $H_0$|   Correct (True Positive)    | Type I Error (False Positive) |\n",
    "|     **Accept** $H_0$|Type II Error (False Negative) |    Correct (True Negative)    | \n",
    "\n",
    "We will be revisiting these when talking about confusion matrices for classification model validation a little later.\n",
    "\n",
    "When one is testing multiple hypotheses at the same time, the chance of these types of errors increases. One method to control errors is the **Bonferroni Correction**: suppose we have hypotheses $H_1,\\ldots,H_n$ with corresponding p-values that we have chosen $p_1,\\ldots,p_n$.  If we want to control the probability of making at least one Type I error to be at most $\\alpha$, then the Bonferroni Correction tells us to reject all null hypotheses where $p_i \\leqslant \\frac{\\alpha}{n}$.  For example, if we had 10 hypotheses and our desired control level was $0.05$, then we would assess each hypothesis at the significance level of $0.05/10 = 0.005$. (Question:  what issues can arise by doing this?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2jMTrfXqJ16"
   },
   "source": [
    "# Assignment 6\n",
    "1. Definition reminder: given a time-series data set, with an $N$-period moving average $\\mu_N$ and an $N$-period standard deviation $\\sigma_N$, the *K-Upper Bollinger Bands* are defined as the rolling computation $(\\mu_N + K\\sigma_N)$ for some $K=1,2,\\ldots$. Similarly, the *K-Lower Bollinger Bands* are $(\\mu_N - K\\sigma_N)$.  Load in the `timeseries_1.csv` price series, and create two new columns which are the first upper and lower Bollinger bands on a 4-minute level computed on the *open* price.  Create another column which has `True` if the high of any given minute is above the upper Bollinger band value, and `False` if not.\n",
    "2. Consider the following set of data:<br>\n",
    "`[ 31.64318274,  52.38028382,  52.06990842,  49.38683521, 66.2809943,  56.28673623,  56.31535831,  47.61107798, 51.22059076,  72.74444307,  44.92132396,  44.7806115 ,55.06875272,  53.30195541,  48.82836245,  56.5645093 ,58.60658527,  51.25941697,  31.19829968,  71.44567964,  50.90570844,  41.50918145,  46.12808914,  38.29642645, 74.76853757,  56.09746354,  49.40810407,  41.91971301,  59.79453349,  71.42976646,  84.08722246,  66.11230252, 52.09783487,  66.50079773,  47.23055517,  42.41625807,  34.99316584,  39.61756471,  51.67965582,  57.67403776, 60.54283988,  40.30238293,  46.61520191,  55.6952267 ,  43.87997719,  45.23675992,  59.35864021,  31.31812861, 74.5603146 , 62.91095588]`<br>\n",
    "Use the Interquartile Method to find any possible outliers.  If there are any outliers, how many standard deviations away from the mean are they?\n",
    "3. Load up the file `cordf.csv` file to answer these questions.\n",
    "  1.  Create a correlation matrix to describe how the variables in this file are correlated to each other. Which pair of columns is the most correlated? Which is the least? Note the ambiguity in this question: what does it mean for one pair to be \"more correlated\" than another?\n",
    "  2.  Create 5 scatterplots with the variable U on the x-axis in each, and the rest of the variables on the y-axes. Describe the relationship between the variables in each scatterplot. Compare and contrast your findings with the expectations you formed in question 1. Note: pandas has a cool function in pandas.plotting.scattermatrix that can do this kind of thing really fast. Make all the scatterplots by hand this time around, but play around with scattermatrix too when you're done to see how it works. Check out the docs here: http://pandas.pydata.org/pandas-docs/stable/visualization.html?highlight=color#scatter-matrix-plot\n",
    "  3.  Taking what you find in parts 1 and 2 together, what can you surmise about what exactly is measured by the correlation coefficient? What do you think you can say about the relationship between two variables if the correlation coefficient is close to 1? Close to -1? Close to 0?\n",
    "  4.  Are there transformations that you could apply to any of the variables V, W, X, Y, or Z such that the transformed variables would have a higher correlation with U? Why or why not?\n",
    "4. Consider the data set <br>\n",
    "`dfcl = pd.DataFrame({'CL Price': [35, 63, 48, 46, 66, 65, 35, 65, 50, 68, 43, 57, 39, 35, 68, 95, 56, 50, 42, 38, 47, 42, 39, 44, 52, 68, 49, 34, 39, 59, 60, 60, 60, 63, 58, 38, 37, 33, 36, 64, 38, 51, 60, 62, 65, 43, 38, 41, 48, 61]}`.<br>\n",
    "Are there any values more than 3 standard deviations away from the mean? If so, can we conclude they are outliers?\n",
    "5.  1.  You flip a coin $n$ times and it comes up heads on each flip. Use the hypothesis testing framework to create a statistical test that will allow you to decide if the coin is biased. How big does $n$ need to be in order to decide that the evidence is significant evidence that the coin is biased? (The ambiguity here is intentional: what does it mean for evidence to be significant?)\n",
    "   2.   You flip another coin $n$ times and it comes up tails 48% of the time. Use the hypothesis testing to create a statistical test that will allow you to decide if the coin is biased. How big does $n$ need to be for significance? [<em>Important hints for this one</em>. Computing exact p-values like we did in question 1 will probably be infeasible here (why?), so we'll need to use a different method. Notice that we can compute the proportion of tails that come up by encoding the flips with a 1 for tails and 0 for heads, and taking the <em>mean</em> of that. Since the proportion of tails is computed as a <em>sample mean</em>, we get to use the central limit theorem, which says that the proportion of tails (approximately) follows a normal distribution with mean equal to the true mean, and standard deviation equal to the true standard deviation divided by $\\sqrt{n}$].\n",
    "   3.  Based on your answers from 1 and 2, what can you say about the relationship between sample size and statistical significance?\n",
    "\n",
    "4. (Bonus) Part of the definition of a vector space (see the appendix if you're interested) is that every vector space must have what is called an *identity* element.  The property this satisfies is that if you add the identity to any other vector, you get that other vector back again, unchanged.  For $\\mathbb{R}^n$, what would the identity element be?  Prove it in general.\n",
    "5. (Bonus) Using the definitions we have provided for conditional probability, derive Bayes' Theorem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"container\" style=\"position:relative;\">\n",
    "<div style=\"position:relative; float:right\"><img style=\"height:25px\"\"width: 50px\" src =\"https://drive.google.com/uc?export=view&id=14VoXUJftgptWtdNhtNYVm6cjVmEWpki1\" />\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Unit 06 - Statistics and Probability.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
